{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3140f1d1-3a9a-4bf4-9a5f-016404b0a72f",
   "metadata": {},
   "source": [
    "# 1. Tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28f0f90-cbb8-4123-ba0d-52a3d9e2bd0c",
   "metadata": {},
   "source": [
    "## A. UCI Adult Income dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57a68533-69e5-4ba1-94ae-84e092f900cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\adult.csv\n",
      "Saved normalized dataset: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\adult.csv\n",
      "Shape: (48842, 15)\n",
      "Columns: ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'] ...\n",
      "income\n",
      "<=50K    37155\n",
      ">50K     11687\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Adult Income Dataset (UCI Census Income dataset)\n",
    "# - Task: predict whether an individual's income exceeds $50K/year based on census attributes.\n",
    "# - Importance: widely used in bias/fairness studies; known gender and race disparities.\n",
    "# - Source: UCI ML Repository, mirrored on OpenML.\n",
    "# - Behavior: load local data/adult.csv if present; otherwise fetch from OpenML.\n",
    "#   In both cases, normalize the target column to 'income' and strip whitespace.\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "adult_csv = data_dir / \"adult.csv\"\n",
    "\n",
    "# Load or fetch\n",
    "if adult_csv.exists():\n",
    "    df = pd.read_csv(adult_csv)\n",
    "    print(f\"Loaded existing: {adult_csv}\")\n",
    "else:\n",
    "    adult = fetch_openml(name=\"adult\", version=2, as_frame=True)\n",
    "    df = adult.frame.copy()\n",
    "    print(\"Fetched Adult Income from OpenML.\")\n",
    "\n",
    "# Normalize target column name and values\n",
    "if \"income\" not in df.columns and \"class\" in df.columns:\n",
    "    df = df.rename(columns={\"class\": \"income\"})\n",
    "if \"income\" in df.columns:\n",
    "    df[\"income\"] = df[\"income\"].astype(str).str.strip()\n",
    "\n",
    "# Save normalized copy\n",
    "df.to_csv(adult_csv, index=False)\n",
    "print(f\"Saved normalized dataset: {adult_csv}\")\n",
    "\n",
    "# Quick overview\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns)[:15], \"...\")\n",
    "if \"income\" in df.columns:\n",
    "    print(df[\"income\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "708f2ffd-aaea-47a6-97d7-08286639a820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model-ready file: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\adult_model.csv  | rows=45222  cols=14\n",
      "EDA summaries written to: C:\\Users\\hana1\\Documents\\iva-bias-project\\results\\eda\n"
     ]
    }
   ],
   "source": [
    "# Prepare a model-ready Adult Income CSV and minimal EDA summaries.\n",
    "# - Input:  data/adult.csv  (raw, normalized to have 'income')\n",
    "# - Output: data/adult_model.csv  (selected features + binary target 'label')\n",
    "# - EDA:    results/eda/* balance tables for target and sensitive attributes\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "results_eda = project_root / \"results\" / \"eda\"\n",
    "results_eda.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "src = data_dir / \"adult.csv\"\n",
    "dst = data_dir / \"adult_model.csv\"\n",
    "\n",
    "# Load raw (normalized) Adult dataset\n",
    "df = pd.read_csv(src)\n",
    "\n",
    "# Standardize target column\n",
    "if \"income\" not in df.columns and \"class\" in df.columns:\n",
    "    df = df.rename(columns={\"class\": \"income\"})\n",
    "df[\"income\"] = df[\"income\"].astype(str).str.strip()\n",
    "\n",
    "# Binary target: 1 iff income > 50K, else 0\n",
    "df[\"label\"] = (df[\"income\"] == \">50K\").astype(int)\n",
    "\n",
    "# Feature selection (exclude technical fields like 'fnlwgt')\n",
    "candidate_features = [\n",
    "    \"age\", \"workclass\", \"education\", \"education-num\", \"marital-status\",\n",
    "    \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "    \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\",\n",
    "]\n",
    "features = [c for c in candidate_features if c in df.columns]\n",
    "cols = features + [\"label\"]\n",
    "\n",
    "clean = df[cols].dropna().reset_index(drop=True)\n",
    "clean.to_csv(dst, index=False)\n",
    "\n",
    "# Minimal EDA summaries (counts and fractions)\n",
    "def counts_and_frac(s: pd.Series) -> pd.DataFrame:\n",
    "    vc = s.value_counts(dropna=False)\n",
    "    frac = (vc / vc.sum()).round(4)\n",
    "    return pd.DataFrame({\"count\": vc, \"fraction\": frac})\n",
    "\n",
    "counts_and_frac(clean[\"label\"]).to_csv(results_eda / \"adult_target_balance.csv\")\n",
    "if \"sex\" in clean.columns:\n",
    "    counts_and_frac(clean[\"sex\"]).to_csv(results_eda / \"adult_sensitive_sex_balance.csv\")\n",
    "if \"race\" in clean.columns:\n",
    "    counts_and_frac(clean[\"race\"]).to_csv(results_eda / \"adult_sensitive_race_balance.csv\")\n",
    "\n",
    "print(f\"Saved model-ready file: {dst}  | rows={len(clean)}  cols={len(clean.columns)}\")\n",
    "print(\"EDA summaries written to:\", results_eda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec93446d-07ea-4dfc-918c-c94d669f3283",
   "metadata": {},
   "source": [
    "## B. COMPAS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62937b4b-dea7-4a4d-b857-7de3c706de71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\compas.csv\n",
      "Saved normalized dataset: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\compas.csv\n",
      "Shape: (7214, 53)\n",
      "Columns: ['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob', 'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score', 'juv_misd_count', 'juv_other_count', 'priors_count'] ...\n",
      "\n",
      "Target distribution (two_year_recid):\n",
      "                count  fraction\n",
      "two_year_recid                 \n",
      "0                3963    0.5493\n",
      "1                3251    0.4507\n",
      "\n",
      "Sex distribution:\n",
      "        count  fraction\n",
      "sex                    \n",
      "Male     5819    0.8066\n",
      "Female   1395    0.1934\n",
      "\n",
      "Race distribution:\n",
      "                  count  fraction\n",
      "race                             \n",
      "African-American   3696    0.5123\n",
      "Caucasian          2454    0.3402\n",
      "Hispanic            637    0.0883\n",
      "Other               377    0.0523\n",
      "Asian                32    0.0044\n",
      "Native American      18    0.0025\n"
     ]
    }
   ],
   "source": [
    "# COMPAS Recidivism dataset (ProPublica)\n",
    "# - Task: predict whether a defendant re-offends within two years.\n",
    "# - Importance: benchmark dataset for fairness studies due to racial disparities.\n",
    "# - Source: ProPublica GitHub (https://github.com/propublica/compas-analysis)\n",
    "# - Behavior: download CSV if not already saved locally, normalize columns, and save to data/compas.csv.\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "compas_csv = data_dir / \"compas.csv\"\n",
    "\n",
    "if compas_csv.exists():\n",
    "    df = pd.read_csv(compas_csv)\n",
    "    print(f\"Loaded existing: {compas_csv}\")\n",
    "else:\n",
    "    url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "    df = pd.read_csv(url)\n",
    "    df.to_csv(compas_csv, index=False)\n",
    "    print(f\"Downloaded & saved: {compas_csv}\")\n",
    "\n",
    "# Standardize key columns\n",
    "if \"two_year_recid\" not in df.columns and \"is_recid\" in df.columns:\n",
    "    df = df.rename(columns={\"is_recid\": \"two_year_recid\"})\n",
    "df[\"two_year_recid\"] = pd.to_numeric(df[\"two_year_recid\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "for col in [\"race\", \"sex\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "df.to_csv(compas_csv, index=False)\n",
    "print(f\"Saved normalized dataset: {compas_csv}\")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns)[:15], \"...\")\n",
    "print(\"\\nTarget distribution (two_year_recid):\")\n",
    "print(df[\"two_year_recid\"].value_counts().sort_index().to_frame(\"count\").assign(\n",
    "    fraction=lambda x: (x[\"count\"] / x[\"count\"].sum()).round(4)\n",
    "))\n",
    "if \"sex\" in df.columns:\n",
    "    print(\"\\nSex distribution:\")\n",
    "    print(df[\"sex\"].value_counts().to_frame(\"count\").assign(\n",
    "        fraction=lambda x: (x[\"count\"] / x[\"count\"].sum()).round(4)\n",
    "    ))\n",
    "if \"race\" in df.columns:\n",
    "    print(\"\\nRace distribution:\")\n",
    "    print(df[\"race\"].value_counts().to_frame(\"count\").assign(\n",
    "        fraction=lambda x: (x[\"count\"] / x[\"count\"].sum()).round(4)\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea3c924c-bd42-4333-8b4a-bcb9cf593c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model-ready file: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\compas_model.csv  | rows=7214  cols=10\n",
      "EDA summaries written to: C:\\Users\\hana1\\Documents\\iva-bias-project\\results\\eda\n"
     ]
    }
   ],
   "source": [
    "# Prepare a model-ready COMPAS CSV and minimal EDA summaries.\n",
    "# - Input:  data/compas.csv  (raw, normalized to have 'two_year_recid')\n",
    "# - Output: data/compas_model.csv  (selected features + binary target 'label')\n",
    "# - EDA:    results/eda/* balance tables for target and sensitive attributes\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "results_eda = project_root / \"results\" / \"eda\"\n",
    "results_eda.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "src = data_dir / \"compas.csv\"\n",
    "dst = data_dir / \"compas_model.csv\"\n",
    "\n",
    "df = pd.read_csv(src)\n",
    "\n",
    "# Ensure target column exists and standardize name\n",
    "if \"two_year_recid\" not in df.columns and \"is_recid\" in df.columns:\n",
    "    df = df.rename(columns={\"is_recid\": \"two_year_recid\"})\n",
    "df[\"two_year_recid\"] = pd.to_numeric(df[\"two_year_recid\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# Binary target: 1 if re-offended within two years, 0 otherwise\n",
    "df[\"label\"] = df[\"two_year_recid\"]\n",
    "\n",
    "# Feature selection (exclude identifiers like name, id, dob, etc.)\n",
    "candidate_features = [\n",
    "    \"sex\", \"race\", \"age\", \"age_cat\", \"priors_count\",\n",
    "    \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\", \"decile_score\",\n",
    "]\n",
    "features = [c for c in candidate_features if c in df.columns]\n",
    "cols = features + [\"label\"]\n",
    "\n",
    "clean = df[cols].dropna().reset_index(drop=True)\n",
    "clean.to_csv(dst, index=False)\n",
    "\n",
    "# Minimal EDA summaries: counts and fractions for target/sensitive attributes\n",
    "def counts_and_frac(s: pd.Series) -> pd.DataFrame:\n",
    "    vc = s.value_counts(dropna=False)\n",
    "    frac = (vc / vc.sum()).round(4)\n",
    "    return pd.DataFrame({\"count\": vc, \"fraction\": frac})\n",
    "\n",
    "counts_and_frac(clean[\"label\"]).to_csv(results_eda / \"compas_target_balance.csv\")\n",
    "if \"sex\" in clean.columns:\n",
    "    counts_and_frac(clean[\"sex\"]).to_csv(results_eda / \"compas_sensitive_sex_balance.csv\")\n",
    "if \"race\" in clean.columns:\n",
    "    counts_and_frac(clean[\"race\"]).to_csv(results_eda / \"compas_sensitive_race_balance.csv\")\n",
    "\n",
    "print(f\"Saved model-ready file: {dst}  | rows={len(clean)}  cols={len(clean.columns)}\")\n",
    "print(\"EDA summaries written to:\", results_eda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c22871-421d-46bb-b436-5fe18c48e075",
   "metadata": {},
   "source": [
    "## C. German Credit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccc9e7cc-33ca-4903-9a85-aa6323cf0227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\german.csv\n",
      "Saved normalized dataset: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\german.csv\n",
      "Shape: (1000, 21)\n",
      "Columns: ['checking_status', 'duration', 'credit_history', 'purpose', 'credit_amount', 'savings_status', 'employment', 'installment_commitment', 'personal_status', 'other_parties', 'residence_since', 'property_magnitude', 'age', 'other_payment_plans', 'housing'] ...\n",
      "\n",
      "Target distribution (credit_risk):\n",
      "             count  fraction\n",
      "credit_risk                 \n",
      "good           700       0.7\n",
      "bad            300       0.3\n"
     ]
    }
   ],
   "source": [
    "# German Credit Risk dataset\n",
    "# - Task: predict whether a loan applicant is a good (1) or bad (2) credit risk.\n",
    "# - Importance: widely used in fairness studies (bias across gender, age, etc.).\n",
    "# - Source: UCI / OpenML.\n",
    "# - Behavior: load local data/german.csv if present; otherwise fetch from OpenML.\n",
    "#   Standardizes target column to 'credit_risk'.\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "german_csv = data_dir / \"german.csv\"\n",
    "\n",
    "if german_csv.exists():\n",
    "    df = pd.read_csv(german_csv)\n",
    "    print(f\"Loaded existing: {german_csv}\")\n",
    "else:\n",
    "    german = fetch_openml(name=\"credit-g\", version=1, as_frame=True)\n",
    "    df = german.frame.copy()\n",
    "    df.to_csv(german_csv, index=False)\n",
    "    print(f\"Fetched German Credit from OpenML and saved to: {german_csv}\")\n",
    "\n",
    "# Normalize target\n",
    "if \"credit_risk\" not in df.columns and \"class\" in df.columns:\n",
    "    df = df.rename(columns={\"class\": \"credit_risk\"})\n",
    "\n",
    "df[\"credit_risk\"] = df[\"credit_risk\"].astype(str).str.strip()\n",
    "\n",
    "df.to_csv(german_csv, index=False)\n",
    "print(f\"Saved normalized dataset: {german_csv}\")\n",
    "\n",
    "# Quick overview\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns)[:15], \"...\")\n",
    "print(\"\\nTarget distribution (credit_risk):\")\n",
    "print(df[\"credit_risk\"].value_counts().to_frame(\"count\").assign(\n",
    "    fraction=lambda x: (x[\"count\"] / x[\"count\"].sum()).round(4)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "785749fd-4d96-472f-9a6c-7c572bc27407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model-ready file: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\german_model.csv  | rows=1000  cols=23\n",
      "EDA summaries written to: C:\\Users\\hana1\\Documents\\iva-bias-project\\results\\eda\n"
     ]
    }
   ],
   "source": [
    "# Prepare a model-ready German Credit CSV and minimal EDA summaries.\n",
    "# - Input:  data/german.csv  (raw, normalized to have 'credit_risk')\n",
    "# - Output: data/german_model.csv  (selected features + binary target 'label')\n",
    "# - EDA:    results/eda/* balance tables for target and sensitive attributes\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "results_eda = project_root / \"results\" / \"eda\"\n",
    "results_eda.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "src = data_dir / \"german.csv\"\n",
    "dst = data_dir / \"german_model.csv\"\n",
    "\n",
    "df = pd.read_csv(src)\n",
    "\n",
    "# Standardize target to binary label (1=good, 0=bad)\n",
    "if \"credit_risk\" not in df.columns and \"class\" in df.columns:\n",
    "    df = df.rename(columns={\"class\": \"credit_risk\"})\n",
    "df[\"credit_risk\"] = df[\"credit_risk\"].astype(str).str.strip().str.lower()\n",
    "df[\"label\"] = (df[\"credit_risk\"] == \"good\").astype(int)\n",
    "\n",
    "# Derive sensitive attributes\n",
    "# - sex: parsed from 'personal_status' values like 'male div/sep' or 'female div/dep/mar'\n",
    "if \"personal_status\" in df.columns and \"sex\" not in df.columns:\n",
    "    def _sex_from_personal_status(x: str) -> str:\n",
    "        x = str(x).lower()\n",
    "        if x.startswith(\"male\"):\n",
    "            return \"Male\"\n",
    "        if x.startswith(\"female\"):\n",
    "            return \"Female\"\n",
    "        return \"Unknown\"\n",
    "    df[\"sex\"] = df[\"personal_status\"].map(_sex_from_personal_status)\n",
    "\n",
    "# - age_group: coarse bins\n",
    "if \"age\" in df.columns and \"age_group\" not in df.columns:\n",
    "    bins = [-1, 24, 34, 44, 54, 120]\n",
    "    labels = [\"<25\", \"25-34\", \"35-44\", \"45-54\", \"55+\"]\n",
    "    df[\"age_group\"] = pd.cut(df[\"age\"], bins=bins, labels=labels)\n",
    "\n",
    "# Feature selection (tabular baseline)\n",
    "candidate_features = [\n",
    "    \"checking_status\", \"duration\", \"credit_history\", \"purpose\", \"credit_amount\",\n",
    "    \"savings_status\", \"employment\", \"installment_commitment\", \"personal_status\",\n",
    "    \"other_parties\", \"residence_since\", \"property_magnitude\", \"age\",\n",
    "    \"other_payment_plans\", \"housing\", \"existing_credits\", \"job\",\n",
    "    \"num_dependents\", \"own_telephone\", \"foreign_worker\",\n",
    "    # derived\n",
    "    \"sex\", \"age_group\",\n",
    "]\n",
    "features = [c for c in candidate_features if c in df.columns]\n",
    "cols = features + [\"label\"]\n",
    "\n",
    "clean = df[cols].dropna().reset_index(drop=True)\n",
    "clean.to_csv(dst, index=False)\n",
    "\n",
    "# Minimal EDA summaries\n",
    "def counts_and_frac(s: pd.Series) -> pd.DataFrame:\n",
    "    vc = s.value_counts(dropna=False)\n",
    "    frac = (vc / vc.sum()).round(4)\n",
    "    return pd.DataFrame({\"count\": vc, \"fraction\": frac})\n",
    "\n",
    "counts_and_frac(clean[\"label\"]).to_csv(results_eda / \"german_target_balance.csv\")\n",
    "if \"sex\" in clean.columns:\n",
    "    counts_and_frac(clean[\"sex\"]).to_csv(results_eda / \"german_sensitive_sex_balance.csv\")\n",
    "if \"age_group\" in clean.columns:\n",
    "    counts_and_frac(clean[\"age_group\"]).to_csv(results_eda / \"german_sensitive_age_balance.csv\")\n",
    "\n",
    "print(f\"Saved model-ready file: {dst}  | rows={len(clean)}  cols={len(clean.columns)}\")\n",
    "print(\"EDA summaries written to:\", results_eda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42343002-5646-4ab0-97ab-f396af86e0e8",
   "metadata": {},
   "source": [
    "# 2. NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c4a03-e64d-4454-b717-bf49360936d3",
   "metadata": {},
   "source": [
    "## A. BOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a81605a5-9c6e-4d00-b1ed-a456ed1cf5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\bold.csv\n",
      "Shape: (7201, 3)\n",
      "Columns: ['text', 'category', 'split']\n",
      "\n",
      "Category balance (top 20):\n",
      "                               count  fraction\n",
      "category                                      \n",
      "European_Americans              2029    0.2818\n",
      "American_actors                 1587    0.2204\n",
      "American_actresses               776    0.1078\n",
      "African_Americans                721    0.1001\n",
      "Asian_Americans                  408    0.0567\n",
      "engineering_branches             248    0.0344\n",
      "nationalism                      115    0.0160\n",
      "dance_occupations                106    0.0147\n",
      "sewing_occupations               104    0.0144\n",
      "nursing_specialties               92    0.0128\n",
      "theatre_personnel                 86    0.0119\n",
      "democracy                         70    0.0097\n",
      "scientific_occupations            69    0.0096\n",
      "anarchism                         62    0.0086\n",
      "socialism                         58    0.0081\n",
      "healthcare_occupations            49    0.0068\n",
      "corporate_titles                  48    0.0067\n",
      "metalworking_occupations          43    0.0060\n",
      "entertainer_occupations           40    0.0056\n",
      "Hispanic_and_Latino_Americans     38    0.0053\n"
     ]
    }
   ],
   "source": [
    "# BOLD (Bias in Open-Ended Language Generation)\n",
    "# - Task: probe social biases in text generation across demographic axes.\n",
    "# - Source: Hugging Face Datasets (AmazonScience/bold).\n",
    "# - Output: data/bold.csv (consolidated text + metadata)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "bold_csv = data_dir / \"bold.csv\"\n",
    "\n",
    "# Load and concatenate available split(s)\n",
    "frames = []\n",
    "ds = load_dataset(\"AmazonScience/bold\")\n",
    "for split in ds.keys():  # typically 'train'\n",
    "    df_split = pd.DataFrame(ds[split])\n",
    "    df_split[\"split\"] = split\n",
    "    frames.append(df_split)\n",
    "df = pd.concat(frames, axis=0, ignore_index=True)\n",
    "\n",
    "# Normalize text column name\n",
    "if \"prompt\" in df.columns and \"text\" not in df.columns:\n",
    "    df = df.rename(columns={\"prompt\": \"text\"})\n",
    "if \"prompts\" in df.columns and \"text\" not in df.columns:\n",
    "    df = df.rename(columns={\"prompts\": \"text\"})\n",
    "\n",
    "# Keep informative columns\n",
    "candidate_cols = [\n",
    "    \"text\", \"category\", \"subcategory\", \"topic\", \"template\", \"target\",\n",
    "    \"demographic\", \"geo\", \"source\", \"split\",\n",
    "]\n",
    "cols = [c for c in candidate_cols if c in df.columns]\n",
    "if \"text\" in df.columns and \"text\" not in cols:\n",
    "    cols = [\"text\"] + cols\n",
    "df = df[cols].dropna(subset=[cols[0]]).reset_index(drop=True)\n",
    "\n",
    "df.to_csv(bold_csv, index=False)\n",
    "print(f\"Saved: {bold_csv}\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "if \"category\" in df.columns:\n",
    "    print(\"\\nCategory balance (top 20):\")\n",
    "    print(df[\"category\"].value_counts().to_frame(\"count\").assign(\n",
    "        fraction=lambda x: (x[\"count\"]/x[\"count\"].sum()).round(4)\n",
    "    ).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa7ad12c-14e5-4b67-93da-c4fb575cff80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model-ready file: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\bold_model.csv  | rows=7201  cols=2\n",
      "EDA summaries written to: C:\\Users\\hana1\\Documents\\iva-bias-project\\results\\eda\n"
     ]
    }
   ],
   "source": [
    "# Prepare a model-ready BOLD CSV and minimal EDA summaries.\n",
    "# - Input:  data/bold.csv  (text + metadata)\n",
    "# - Output: data/bold_model.csv  (text + group column for analysis)\n",
    "# - EDA:    results/eda/bold_group_balance.csv\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "results_eda = project_root / \"results\" / \"eda\"\n",
    "results_eda.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "src = data_dir / \"bold.csv\"\n",
    "dst = data_dir / \"bold_model.csv\"\n",
    "\n",
    "df = pd.read_csv(src)\n",
    "\n",
    "# Standardize columns: use 'text' and map 'category' -> 'group' for downstream analysis\n",
    "df = df.rename(columns={\"category\": \"group\"})\n",
    "keep_cols = [c for c in [\"text\", \"group\"] if c in df.columns]\n",
    "clean = df[keep_cols].dropna(subset=[\"text\"]).reset_index(drop=True)\n",
    "\n",
    "# Persist model-ready file\n",
    "clean.to_csv(dst, index=False)\n",
    "\n",
    "# Minimal EDA: group balance\n",
    "def counts_and_frac(s: pd.Series) -> pd.DataFrame:\n",
    "    vc = s.value_counts(dropna=False)\n",
    "    frac = (vc / vc.sum()).round(4)\n",
    "    return pd.DataFrame({\"count\": vc, \"fraction\": frac})\n",
    "\n",
    "if \"group\" in clean.columns:\n",
    "    counts_and_frac(clean[\"group\"]).to_csv(results_eda / \"bold_group_balance.csv\")\n",
    "\n",
    "print(f\"Saved model-ready file: {dst}  | rows={len(clean)}  cols={len(clean.columns)}\")\n",
    "print(\"EDA summaries written to:\", results_eda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f960d85-4fcd-4216-b839-d86d2881899f",
   "metadata": {},
   "source": [
    "## C. WinoBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64ee6682-b6f3-4b8f-9589-d094431cfc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\winobias.csv\n",
      "Shape: (3168, 3)\n",
      "Columns: ['text', 'group', 'split']\n",
      "\n",
      "Group balance:\n",
      "group\n",
      "type1_pro     792\n",
      "type1_anti    792\n",
      "type2_pro     792\n",
      "type2_anti    792\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# WinoBias (Gender bias in coreference-style sentences)\n",
    "# - Task: evaluate gender/occupation bias via pro/anti-stereotype minimal pairs.\n",
    "# - Source: Hugging Face Datasets (uclanlp/wino_bias, configs: type1_pro, type1_anti, type2_pro, type2_anti).\n",
    "# - Output: data/winobias.csv (text + group + split).\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "wb_csv = data_dir / \"winobias.csv\"\n",
    "\n",
    "frames = []\n",
    "for cfg in [\"type1_pro\", \"type1_anti\", \"type2_pro\", \"type2_anti\"]:\n",
    "    ds = load_dataset(\"uclanlp/wino_bias\", cfg)\n",
    "    for split in ds.keys():  # usually 'train' and 'test'\n",
    "        df_split = pd.DataFrame(ds[split])\n",
    "        df_split[\"config\"] = cfg\n",
    "        df_split[\"split\"] = split\n",
    "        frames.append(df_split)\n",
    "\n",
    "df = pd.concat(frames, axis=0, ignore_index=True)\n",
    "\n",
    "# Create text column from tokens\n",
    "if \"tokens\" in df.columns and \"text\" not in df.columns:\n",
    "    df[\"text\"] = df[\"tokens\"].apply(lambda xs: \" \".join(xs))\n",
    "\n",
    "# Standardize group column (pro/anti + type1/type2 from config)\n",
    "df[\"group\"] = df[\"config\"]\n",
    "\n",
    "# Keep only relevant cols\n",
    "cols = [\"text\", \"group\", \"split\"]\n",
    "df = df[cols].dropna(subset=[\"text\"]).reset_index(drop=True)\n",
    "\n",
    "df.to_csv(wb_csv, index=False)\n",
    "print(f\"Saved: {wb_csv}\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "print(\"\\nGroup balance:\")\n",
    "print(df[\"group\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfb36cb0-3c05-480a-827c-a4f11abc8a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model-ready file: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\winobias_model.csv  | rows=3168  cols=3\n",
      "EDA summaries written to: C:\\Users\\hana1\\Documents\\iva-bias-project\\results\\eda\n"
     ]
    }
   ],
   "source": [
    "# Prepare a model-ready WinoBias CSV and minimal EDA summaries.\n",
    "# - Input:  data/winobias.csv  (text + group + split)\n",
    "# - Output: data/winobias_model.csv  (text + group + split)\n",
    "# - EDA:    results/eda/winobias_group_balance.csv\n",
    "#           results/eda/winobias_split_balance.csv\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "results_eda = project_root / \"results\" / \"eda\"\n",
    "results_eda.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "src = data_dir / \"winobias.csv\"\n",
    "dst = data_dir / \"winobias_model.csv\"\n",
    "\n",
    "df = pd.read_csv(src)\n",
    "\n",
    "# Standardize to the columns used downstream\n",
    "keep_cols = [c for c in [\"text\", \"group\", \"split\"] if c in df.columns]\n",
    "clean = df[keep_cols].dropna(subset=[\"text\"]).reset_index(drop=True)\n",
    "clean.to_csv(dst, index=False)\n",
    "\n",
    "# Minimal EDA summaries\n",
    "def counts_and_frac(s: pd.Series) -> pd.DataFrame:\n",
    "    vc = s.value_counts(dropna=False)\n",
    "    frac = (vc / vc.sum()).round(4)\n",
    "    return pd.DataFrame({\"count\": vc, \"fraction\": frac})\n",
    "\n",
    "counts_and_frac(clean[\"group\"]).to_csv(results_eda / \"winobias_group_balance.csv\")\n",
    "if \"split\" in clean.columns:\n",
    "    counts_and_frac(clean[\"split\"]).to_csv(results_eda / \"winobias_split_balance.csv\")\n",
    "\n",
    "print(f\"Saved model-ready file: {dst}  | rows={len(clean)}  cols={len(clean.columns)}\")\n",
    "print(\"EDA summaries written to:\", results_eda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf3c0fb-b98e-44f3-8ae5-88ef83d1cd51",
   "metadata": {},
   "source": [
    "## C. Equity Evaluation Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcfa3628-cd60-4d6a-a485-d2bbf92c50ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\eec.csv\n",
      "Shape: (8640, 8)\n",
      "Columns: ['text', 'person', 'gender', 'race', 'emotion', 'emotion_word', 'template', 'split']\n",
      "\n",
      "Race|Person balance (top 12):\n",
      "                             count  fraction\n",
      "African-American | Alonzo      144    0.0167\n",
      "African-American | Jamel       144    0.0167\n",
      "African-American | Alphonse    144    0.0167\n",
      "African-American | Jerome      144    0.0167\n",
      "African-American | Leroy       144    0.0167\n",
      "African-American | Torrance    144    0.0167\n",
      "African-American | Darnell     144    0.0167\n",
      "African-American | Lamar       144    0.0167\n",
      "African-American | Malik       144    0.0167\n",
      "African-American | Terrence    144    0.0167\n",
      "European | Adam                144    0.0167\n",
      "European | Harry               144    0.0167\n"
     ]
    }
   ],
   "source": [
    "# Equity Evaluation Corpus (EEC)\n",
    "# - Task: Detect and analyze implicit bias in English sentences containing emotional expressions.\n",
    "# - Content: 8,640 sentences that pair emotion-related words with demographic names \n",
    "#            (e.g., “African-American | Alonzo” or “European | Adam”), labeled by gender and race.\n",
    "# - Importance: Used in fairness research to measure differences in sentiment across demographic groups.\n",
    "# - Source: Hugging Face dataset repo (peixian/equity_evaluation_corpus).\n",
    "# - Behavior: Fetch direct CSV version (robust to Hugging Face script changes) \n",
    "#             and standardize to columns: text, person, gender, race, emotion, emotion_word, template, split.\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "eec_csv = data_dir / \"eec.csv\"\n",
    "\n",
    "# Direct CSV (same content as the dataset viewer's 'first_domain/train')\n",
    "csv_url = \"https://huggingface.co/datasets/peixian/equity_evaluation_corpus/resolve/main/Equity-Evaluation-Corpus.csv\"\n",
    "\n",
    "# Load and standardize headers (case-insensitive)\n",
    "df_raw = pd.read_csv(csv_url)\n",
    "df = df_raw.copy()\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "# Map canonical column names\n",
    "rename_map = {\n",
    "    \"sentence\": \"text\",\n",
    "    \"emotion word\": \"emotion_word\",\n",
    "}\n",
    "df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
    "\n",
    "# Keep informative columns if present\n",
    "candidate_cols = [\"text\", \"person\", \"gender\", \"race\", \"emotion\", \"emotion_word\", \"template\"]\n",
    "cols = [c for c in candidate_cols if c in df.columns]\n",
    "df = df[cols].copy()\n",
    "\n",
    "# Light cleanup\n",
    "for c in df.columns:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# Add a split column to match our convention (EEC is a single split)\n",
    "df[\"split\"] = \"train\"\n",
    "\n",
    "# Persist\n",
    "df.to_csv(eec_csv, index=False)\n",
    "print(f\"Saved: {eec_csv}\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "if {\"race\",\"person\"}.issubset(df.columns):\n",
    "    grp = (df[\"race\"] + \" | \" + df[\"person\"]).value_counts().to_frame(\"count\")\n",
    "    grp[\"fraction\"] = (grp[\"count\"]/grp[\"count\"].sum()).round(4)\n",
    "    print(\"\\nRace|Person balance (top 12):\")\n",
    "    print(grp.head(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7270d16e-f820-4aa1-aaed-a6be7b8792e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model-ready file: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\eec_model.csv  | rows=8640  cols=5\n",
      "EDA summaries written to: C:\\Users\\hana1\\Documents\\iva-bias-project\\results\\eda\n"
     ]
    }
   ],
   "source": [
    "# Equity Evaluation Corpus (EEC) — model-ready export + EDA\n",
    "# - Input:  data/eec.csv\n",
    "# - Output: data/eec_model.csv  (text, race, gender, emotion, split)\n",
    "# - EDA:    results/eda/eec_race_balance.csv\n",
    "#           results/eda/eec_gender_balance.csv\n",
    "#           results/eda/eec_emotion_balance.csv\n",
    "#           results/eda/eec_race_gender_balance.csv\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "results_eda = project_root / \"results\" / \"eda\"\n",
    "results_eda.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "src = data_dir / \"eec.csv\"\n",
    "dst = data_dir / \"eec_model.csv\"\n",
    "\n",
    "df = pd.read_csv(src)\n",
    "\n",
    "# Standard columns for downstream use\n",
    "keep_cols = [c for c in [\"text\", \"race\", \"gender\", \"emotion\", \"split\"] if c in df.columns]\n",
    "clean = df[keep_cols].dropna(subset=[\"text\"]).reset_index(drop=True)\n",
    "clean.to_csv(dst, index=False)\n",
    "\n",
    "# EDA helpers\n",
    "def counts_and_frac(s: pd.Series) -> pd.DataFrame:\n",
    "    vc = s.value_counts(dropna=False)\n",
    "    frac = (vc / vc.sum()).round(4)\n",
    "    return pd.DataFrame({\"count\": vc, \"fraction\": frac})\n",
    "\n",
    "# EDA outputs\n",
    "if \"race\" in clean.columns:\n",
    "    counts_and_frac(clean[\"race\"]).to_csv(results_eda / \"eec_race_balance.csv\")\n",
    "if \"gender\" in clean.columns:\n",
    "    counts_and_frac(clean[\"gender\"]).to_csv(results_eda / \"eec_gender_balance.csv\")\n",
    "if \"emotion\" in clean.columns:\n",
    "    counts_and_frac(clean[\"emotion\"]).to_csv(results_eda / \"eec_emotion_balance.csv\")\n",
    "if {\"race\", \"gender\"}.issubset(clean.columns):\n",
    "    rg = (clean[\"race\"] + \" | \" + clean[\"gender\"]).rename(\"race|gender\")\n",
    "    counts_and_frac(rg).to_csv(results_eda / \"eec_race_gender_balance.csv\")\n",
    "\n",
    "print(f\"Saved model-ready file: {dst}  | rows={len(clean)}  cols={len(clean.columns)}\")\n",
    "print(\"EDA summaries written to:\", results_eda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3109d-ee69-4d77-90f1-33f84ceaec58",
   "metadata": {},
   "source": [
    "# 3 Vision Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cdd7ad-b383-42b0-8550-acd4bde23655",
   "metadata": {},
   "source": [
    "## A. Fairface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0482138c-1e11-4559-a1be-dc5f137fd42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1i1L3Yqwaio7YSOCj7ftgk8ZZchPG7dmH\n",
      "To: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\fairface_label_train.csv\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3.79M/3.79M [00:00<00:00, 3.81MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1wOdja-ezstMEp81tX1a-EYkFebev4h7D\n",
      "To: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\fairface_label_val.csv\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 448k/448k [00:00<00:00, 2.10MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\fairface.csv\n",
      "Shape: (97698, 6)\n",
      "Columns: ['image_file', 'age', 'gender', 'race', 'service_test', 'split']\n",
      "\n",
      "Race | Gender balance (top 12):\n",
      "                          count  fraction\n",
      "White | Male               9823    0.1005\n",
      "White | Female             8789    0.0900\n",
      "Latino_Hispanic | Female   7545    0.0772\n",
      "Latino_Hispanic | Male     7445    0.0762\n",
      "Middle Eastern | Male      7182    0.0735\n",
      "Indian | Male              7163    0.0733\n",
      "East Asian | Male          6923    0.0709\n",
      "East Asian | Female        6914    0.0708\n",
      "Black | Male               6895    0.0706\n",
      "Black | Female             6894    0.0706\n",
      "Indian | Female            6672    0.0683\n",
      "Southeast Asian | Male     6347    0.0650\n"
     ]
    }
   ],
   "source": [
    "# FairFace Dataset\n",
    "# - Task: Evaluate fairness in facial attribute classification (race, gender, age).\n",
    "# - Content: metadata (CSV labels) for ~108k images with 7 race groups.\n",
    "# - Importance: benchmark dataset for bias analysis in computer vision.\n",
    "# - Source: Official label CSVs linked from the FairFace GitHub (Google Drive).\n",
    "# - Behavior: download labels via Google Drive file IDs, normalize, add split, and save one CSV.\n",
    "# - Output: data/fairface.csv with columns [image_file, age, gender, race, service_test, split]\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys, subprocess\n",
    "\n",
    "# Ensure gdown is available for Google Drive downloads\n",
    "try:\n",
    "    import gdown  # type: ignore\n",
    "except Exception:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"gdown\"])\n",
    "    import gdown  # type: ignore\n",
    "\n",
    "# Paths\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "fairface_csv = data_dir / \"fairface.csv\"\n",
    "\n",
    "# Google Drive file IDs from the FairFace GitHub page:\n",
    "#   Train labels: fairface_label_train.csv\n",
    "#   Val labels:   fairface_label_val.csv\n",
    "TRAIN_ID = \"1i1L3Yqwaio7YSOCj7ftgk8ZZchPG7dmH\"\n",
    "VAL_ID   = \"1wOdja-ezstMEp81tX1a-EYkFebev4h7D\"\n",
    "\n",
    "train_path = data_dir / \"fairface_label_train.csv\"\n",
    "val_path   = data_dir / \"fairface_label_val.csv\"\n",
    "\n",
    "# Download if not present locally\n",
    "if not train_path.exists():\n",
    "    gdown.download(id=TRAIN_ID, output=str(train_path), quiet=False)\n",
    "if not val_path.exists():\n",
    "    gdown.download(id=VAL_ID, output=str(val_path), quiet=False)\n",
    "\n",
    "# Load and clean\n",
    "def load_and_tag(p: Path, split_name: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(p)\n",
    "    # Normalize headers: lowercase, underscores\n",
    "    df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "    # Standardize expected column names\n",
    "    # Common FairFace label columns include: file, gender, race, age, service_test\n",
    "    rename_map = {\"file\": \"image_file\"}\n",
    "    df = df.rename(columns=rename_map)\n",
    "    df[\"split\"] = split_name\n",
    "    return df\n",
    "\n",
    "df_train = load_and_tag(train_path, \"train\")\n",
    "df_val   = load_and_tag(val_path, \"val\")\n",
    "\n",
    "# Concatenate and keep a consistent column order\n",
    "df = pd.concat([df_train, df_val], ignore_index=True)\n",
    "candidate_cols = [\"image_file\", \"age\", \"gender\", \"race\", \"service_test\", \"split\"]\n",
    "cols = [c for c in candidate_cols if c in df.columns]\n",
    "df = df[cols].copy()\n",
    "\n",
    "# Save consolidated metadata\n",
    "df.to_csv(fairface_csv, index=False)\n",
    "print(f\"Saved: {fairface_csv}\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# Simple balance check (no images required)\n",
    "if {\"race\",\"gender\"}.issubset(df.columns):\n",
    "    grp = (df[\"race\"].astype(str) + \" | \" + df[\"gender\"].astype(str)).value_counts()\n",
    "    frac = (grp / grp.sum()).round(4)\n",
    "    out = pd.DataFrame({\"count\": grp, \"fraction\": frac})\n",
    "    print(\"\\nRace | Gender balance (top 12):\")\n",
    "    print(out.head(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a9861e-24c0-44be-b3c1-7ad83401f344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model-ready file: C:\\Users\\hana1\\Documents\\iva-bias-project\\data\\fairface_model.csv  | rows=97698  cols=5\n",
      "EDA summaries written to: C:\\Users\\hana1\\Documents\\iva-bias-project\\results\\eda\n"
     ]
    }
   ],
   "source": [
    "# FairFace — model-ready export and EDA\n",
    "# - Input:  data/fairface.csv\n",
    "# - Output: data/fairface_model.csv  (image_file, age, gender, race, split)\n",
    "# - EDA:    results/eda/fairface_race_balance.csv\n",
    "#           results/eda/fairface_gender_balance.csv\n",
    "#           results/eda/fairface_age_balance.csv\n",
    "#           results/eda/fairface_race_gender_balance.csv\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "results_eda = project_root / \"results\" / \"eda\"\n",
    "results_eda.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "src = data_dir / \"fairface.csv\"\n",
    "dst = data_dir / \"fairface_model.csv\"\n",
    "\n",
    "df = pd.read_csv(src)\n",
    "\n",
    "# Keep key demographic fields (images are not downloaded; this is metadata-only)\n",
    "keep_cols = [c for c in [\"image_file\", \"age\", \"gender\", \"race\", \"split\"] if c in df.columns]\n",
    "clean = df[keep_cols].dropna().reset_index(drop=True)\n",
    "clean.to_csv(dst, index=False)\n",
    "\n",
    "def counts_and_frac(s: pd.Series) -> pd.DataFrame:\n",
    "    vc = s.value_counts(dropna=False)\n",
    "    frac = (vc / vc.sum()).round(4)\n",
    "    return pd.DataFrame({\"count\": vc, \"fraction\": frac})\n",
    "\n",
    "# EDA exports\n",
    "if \"race\" in clean.columns:\n",
    "    counts_and_frac(clean[\"race\"]).to_csv(results_eda / \"fairface_race_balance.csv\")\n",
    "if \"gender\" in clean.columns:\n",
    "    counts_and_frac(clean[\"gender\"]).to_csv(results_eda / \"fairface_gender_balance.csv\")\n",
    "if \"age\" in clean.columns:\n",
    "    counts_and_frac(clean[\"age\"]).to_csv(results_eda / \"fairface_age_balance.csv\")\n",
    "if {\"race\", \"gender\"}.issubset(clean.columns):\n",
    "    rg = (clean[\"race\"].astype(str) + \" | \" + clean[\"gender\"].astype(str)).rename(\"race|gender\")\n",
    "    counts_and_frac(rg).to_csv(results_eda / \"fairface_race_gender_balance.csv\")\n",
    "\n",
    "print(f\"Saved model-ready file: {dst}  | rows={len(clean)}  cols={len(clean.columns)}\")\n",
    "print(\"EDA summaries written to:\", results_eda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0260e67-e768-456a-82c3-ebc4c5daa9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
