{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff451889-82d9-4fa5-a10f-ee79374a602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7868 - loss: 0.4637 - val_accuracy: 0.8306 - val_loss: 0.3693\n",
      "Epoch 2/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8357 - loss: 0.3561 - val_accuracy: 0.8404 - val_loss: 0.3391\n",
      "Epoch 3/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8449 - loss: 0.3346 - val_accuracy: 0.8426 - val_loss: 0.3325\n",
      "Epoch 4/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8491 - loss: 0.3287 - val_accuracy: 0.8417 - val_loss: 0.3321\n",
      "Epoch 5/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8506 - loss: 0.3242 - val_accuracy: 0.8433 - val_loss: 0.3283\n",
      "Epoch 6/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8525 - loss: 0.3209 - val_accuracy: 0.8449 - val_loss: 0.3268\n",
      "Epoch 7/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8540 - loss: 0.3177 - val_accuracy: 0.8464 - val_loss: 0.3267\n",
      "Epoch 8/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8522 - loss: 0.3167 - val_accuracy: 0.8464 - val_loss: 0.3271\n",
      "Epoch 9/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8556 - loss: 0.3141 - val_accuracy: 0.8445 - val_loss: 0.3254\n",
      "Epoch 10/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8530 - loss: 0.3124 - val_accuracy: 0.8445 - val_loss: 0.3242\n",
      "Epoch 11/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8550 - loss: 0.3113 - val_accuracy: 0.8435 - val_loss: 0.3245\n",
      "Epoch 12/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8565 - loss: 0.3110 - val_accuracy: 0.8436 - val_loss: 0.3239\n",
      "Epoch 13/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8561 - loss: 0.3098 - val_accuracy: 0.8440 - val_loss: 0.3244\n",
      "Epoch 14/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8584 - loss: 0.3077 - val_accuracy: 0.8439 - val_loss: 0.3238\n",
      "Epoch 15/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8568 - loss: 0.3089 - val_accuracy: 0.8461 - val_loss: 0.3230\n",
      "Epoch 16/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8563 - loss: 0.3070 - val_accuracy: 0.8449 - val_loss: 0.3238\n",
      "Epoch 17/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8567 - loss: 0.3070 - val_accuracy: 0.8473 - val_loss: 0.3231\n",
      "Epoch 18/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8584 - loss: 0.3053 - val_accuracy: 0.8458 - val_loss: 0.3250\n",
      "Epoch 19/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8584 - loss: 0.3049 - val_accuracy: 0.8439 - val_loss: 0.3238\n",
      "Epoch 20/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8605 - loss: 0.3027 - val_accuracy: 0.8454 - val_loss: 0.3239\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step  \n",
      "Overall metrics:\n",
      "   model  accuracy      f1  roc_auc  sex_dp_gap  sex_eopp_gap  race_dp_gap  \\\n",
      "0   dnn    0.8515  0.6777   0.9104       0.192        0.1378       0.1703   \n",
      "\n",
      "   race_eopp_gap  \n",
      "0         0.3187  \n",
      "\n",
      "Saved: C:\\Users\\hana1\\Documents\\iva-bias-project\\results\\metrics\\adult_dnn_overall.csv\n",
      "\n",
      "Sample group metrics:\n",
      "   model attribute               group     n     p_pos  accuracy       tpr\n",
      "0   dnn       sex              Female  3681  0.083401  0.920130  0.514349\n",
      "1   dnn       sex                Male  7625  0.275410  0.818361  0.652192\n",
      "2   dnn      race  Amer-Indian-Eskimo   106  0.094340  0.933962  0.615385\n",
      "3   dnn      race  Asian-Pac-Islander   320  0.259375  0.837500  0.682353\n",
      "4   dnn      race               Black  1044  0.097701  0.909004  0.525547\n",
      "5   dnn      race               Other   101  0.089109  0.881188  0.363636\n",
      "6   dnn      race               White  9735  0.226297  0.844581  0.634977\n",
      "Saved: C:\\Users\\hana1\\Documents\\iva-bias-project\\results\\metrics\\adult_dnn_groups.csv\n",
      "\n",
      "Saved model: C:\\Users\\hana1\\Documents\\iva-bias-project\\models\\adult\\dnn_model.keras\n"
     ]
    }
   ],
   "source": [
    "# Adult Income — Feedforward DNN + fairness metrics\n",
    "# Input :  data/adult_model.csv\n",
    "# Output:  results/metrics/adult_dnn_overall.csv\n",
    "#          results/metrics/adult_dnn_groups.csv\n",
    "#          models/adult/dnn_model.keras\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Paths\n",
    "project_root = Path.cwd().resolve().parent  # run from notebooks/\n",
    "data_dir = project_root / \"data\"\n",
    "results_dir = project_root / \"results\" / \"metrics\"\n",
    "models_dir = project_root / \"models\" / \"adult\"\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(data_dir / \"adult_model.csv\")\n",
    "\n",
    "# Target and features\n",
    "y = df[\"label\"].astype(int).values\n",
    "X = df.drop(columns=[\"label\"]).copy()\n",
    "\n",
    "# Sensitive for fairness reporting\n",
    "sensitive_cols = [c for c in [\"sex\", \"race\"] if c in X.columns]\n",
    "sens_all = X[sensitive_cols].copy() if sensitive_cols else pd.DataFrame(index=X.index)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test, sens_train, sens_test = train_test_split(\n",
    "    X, y, sens_all, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Preprocess: numeric vs categorical\n",
    "num_cols = [c for c in X_train.columns if np.issubdtype(X_train[c].dtype, np.number)]\n",
    "cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
    "\n",
    "# Use sparse_output for newer sklearn\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=False), num_cols),\n",
    "        (\"cat\", ohe, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=1.0,\n",
    ")\n",
    "\n",
    "X_train_m = preprocess.fit_transform(X_train)\n",
    "X_test_m  = preprocess.transform(X_test)\n",
    "\n",
    "# Convert sparse → dense for Keras\n",
    "X_train_m = X_train_m.toarray()\n",
    "X_test_m  = X_test_m.toarray()\n",
    "\n",
    "# DNN\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_m.shape[1],)),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_m, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=512,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_prob = model.predict(X_test_m).ravel()\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "overall = {\n",
    "    \"model\": \"dnn\",\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"f1\": f1_score(y_test, y_pred),\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_prob),\n",
    "}\n",
    "\n",
    "# Fairness per group\n",
    "rows = []\n",
    "if not sens_test.empty:\n",
    "    def tpr(y_true, y_hat):\n",
    "        pos = (y_true == 1).sum()\n",
    "        return ((y_true == 1) & (y_hat == 1)).sum() / pos if pos > 0 else np.nan\n",
    "\n",
    "    for attr in sens_test.columns:\n",
    "        groups = sens_test[attr].astype(str).unique()\n",
    "        per_group = []\n",
    "        for g in sorted(groups):\n",
    "            mask = sens_test[attr].astype(str) == g\n",
    "            yp_g = y_pred[mask]; yt_g = y_test[mask]\n",
    "            p_pos = (yp_g == 1).mean() if len(yp_g) else np.nan\n",
    "            acc = accuracy_score(yt_g, yp_g) if len(yt_g) else np.nan\n",
    "            tpr_g = tpr(yt_g, yp_g) if len(yt_g) else np.nan\n",
    "            per_group.append({\"p_pos\": p_pos, \"tpr\": tpr_g})\n",
    "\n",
    "            rows.append({\n",
    "                \"model\": \"dnn\", \"attribute\": attr, \"group\": g,\n",
    "                \"n\": int(mask.sum()), \"p_pos\": p_pos, \"accuracy\": acc, \"tpr\": tpr_g\n",
    "            })\n",
    "\n",
    "        dp_gap = np.nanmax([r[\"p_pos\"] for r in per_group]) - np.nanmin([r[\"p_pos\"] for r in per_group])\n",
    "        eopp_gap = np.nanmax([r[\"tpr\"] for r in per_group]) - np.nanmin([r[\"tpr\"] for r in per_group])\n",
    "        overall[f\"{attr}_dp_gap\"] = dp_gap\n",
    "        overall[f\"{attr}_eopp_gap\"] = eopp_gap\n",
    "\n",
    "# Save metrics + model\n",
    "overall_df = pd.DataFrame([overall])\n",
    "groups_df = pd.DataFrame(rows) if rows else pd.DataFrame(columns=[\n",
    "    \"model\",\"attribute\",\"group\",\"n\",\"p_pos\",\"accuracy\",\"tpr\"\n",
    "])\n",
    "\n",
    "overall_path = results_dir / \"adult_dnn_overall.csv\"\n",
    "groups_path  = results_dir / \"adult_dnn_groups.csv\"\n",
    "overall_df.to_csv(overall_path, index=False)\n",
    "groups_df.to_csv(groups_path,  index=False)\n",
    "print(\"Overall metrics:\\n\", overall_df.round(4))\n",
    "print(\"\\nSaved:\", overall_path)\n",
    "if not groups_df.empty:\n",
    "    print(\"\\nSample group metrics:\\n\", groups_df.head(12))\n",
    "    print(\"Saved:\", groups_path)\n",
    "\n",
    "model_path = models_dir / \"dnn_model.keras\"\n",
    "model.save(model_path)\n",
    "print(\"\\nSaved model:\", model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df1302a-44aa-49a5-9b49-e5daab6032fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcac19a-1dc2-4504-a746-e2c7b19ef2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
