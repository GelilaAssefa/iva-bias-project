{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bd12451-1aed-4324-a389-38bd3f042054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and standardized:\n",
      "  Layer1: (11306, 64)  -> standardized (11306, 64)\n",
      "  Layer2: (11306, 32)  -> standardized (11306, 32)\n",
      "  Joint : (11306, 96)\n",
      "\n",
      "Metadata preview:\n",
      "      sex   race  y_true    y_prob  y_pred\n",
      "0    Male  White       0  0.097896       0\n",
      "1  Female  White       0  0.012861       0\n",
      "2    Male  White       0  0.182906       0\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Cell 1 â€” Load layer-1 and layer-2 activations + standardize\n",
    "# ----------------------------------------------------------\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Paths\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().resolve().parent\n",
    "act_dir = project_root / \"results\" / \"activations\"\n",
    "\n",
    "# Files produced earlier\n",
    "l1_path = act_dir / \"adult_dnn_layer1.npy\"\n",
    "l2_path = act_dir / \"adult_dnn_layer2.npy\"\n",
    "meta_path = act_dir / \"adult_dnn_metadata.csv\"\n",
    "\n",
    "# Load\n",
    "L1 = np.load(l1_path)          # shape: (n_samples, n_units_l1)\n",
    "L2 = np.load(l2_path)          # shape: (n_samples, n_units_l2)\n",
    "meta = pd.read_csv(meta_path)  # columns: sex, race, y_true, y_prob, y_pred\n",
    "\n",
    "# Basic checks\n",
    "assert L1.shape[0] == L2.shape[0] == len(meta), \"Mismatched sample counts.\"\n",
    "\n",
    "# Standardize each layer (per feature) so neither dominates\n",
    "sc1 = StandardScaler(with_mean=True, with_std=True)\n",
    "sc2 = StandardScaler(with_mean=True, with_std=True)\n",
    "L1z = sc1.fit_transform(L1)\n",
    "L2z = sc2.fit_transform(L2)\n",
    "\n",
    "# Concatenate features from both layers (simple joint view)\n",
    "X_joint = np.hstack([L1z, L2z])   # shape: (n_samples, n_units_l1 + n_units_l2)\n",
    "\n",
    "print(\"Loaded and standardized:\")\n",
    "print(f\"  Layer1: {L1.shape}  -> standardized {L1z.shape}\")\n",
    "print(f\"  Layer2: {L2.shape}  -> standardized {L2z.shape}\")\n",
    "print(f\"  Joint : {X_joint.shape}\")\n",
    "print(\"\\nMetadata preview:\")\n",
    "print(meta.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc9cc3-3672-4d2e-8e24-7a7d829024ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
